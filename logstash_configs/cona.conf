input {
	stdin {}
}

filter {
     
       # For each inbound record, split into the known and unkown fields
       csv {
	   separator => ","
           columns => ["date","time","direct_read_portion","seqential_read_portion","change_portion","avg_resp_time","avg_cpu_time","avg_db_time","avg_wait_time","avg_proc_time","total_dialog_steps","total_resp_time","total_db_time","total_proc_time","total_cpu_time","total_rollwait_time","total_wait_time","total_seq_read_time","total_direct_read_time","total_change_time"]
	}

 
   mutate {
     convert => { "avg_resp_time" => "float" }
     convert => { "avg_cpu_time" => "float" }
     convert => { "avg_wait_time" => "float" }
     convert => { "avg_proc_time" => "float" }
     convert => { "total_dialog_steps" => "float" }
     convert => { "total_resp_time" => "float" }
     convert => { "total_db_time" => "float" }
     convert => { "total_proc_time" => "float" }
     convert => { "total_cpu_time" => "float" }
     convert => { "total_rollwait_time" => "float" }
     convert => { "total_wait_time" => "float" }
     convert => { "total_seq_read_time" => "float" }
     convert => { "total_direct_read_time" => "float" }
     convert => { "total_change_time" => "float" }
   }

   mutate {
    add_field => {
      "timestamp" => "%{date} %{time}"
    }
  }

    date {
    match => ["timestamp", "yyyy-MM-dd HH:mm:ss"]
    remove_field => ["timestamp"]
  }

}

output {
    elasticsearch {
       hosts => ["http://192.168.0.214:9201"]
       user => "elastic"
       password => "Ndg=%BF7swB^D8Qlom5o"
       index => "sap-hourly-%{+YYYY.MM.dd}"
    }
   stdout { codec => rubydebug }
  
}

